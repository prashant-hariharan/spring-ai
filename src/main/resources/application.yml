# In application.yml
---
spring:
  application:
    name: ai-chat-bot
  ai:
    openai:
      api-key: ${OPEN_API_KEY}
      chat:
        enabled: true
        options:
          model: gpt-4o-mini
          temperature: 0.5
          max-tokens: 500
    providers:
      gemini:
        api-key: ${GEMINI_API_KEY}
        model: gemini-2.5-flash
        temperature: 0.5
        max-tokens: 750
        base-url: https://generativelanguage.googleapis.com/v1beta
        completion-path: /openai/chat/completions
      groq:
        api-key: ${GROQ_API_KEY:}
        model: llama-3.1-8b-instant
        temperature: 0.5
        max-tokens: 500
        base-url: https://api.groq.com/openai/v1
        completion-path: /chat/completions
      ollama:
        api-key: ${OLLAMA_API_KEY:}
        model: llama3.2:3b
        temperature: 0.5
        max-tokens: 500
        base-url: http://localhost:11434/v1
        completion-path: /chat/completions
      cohere:
        api-key: ${COHERE_API_KEY:}
        model: command-a-03-2025
        temperature: 0.5
        max-tokens: 500
        base-url: https://api.cohere.ai/compatibility/v1
        completion-path: /chat/completions
      mistral:
        api-key: ${MISTRAL_API_KEY:}
        model: mistral-small-latest
        temperature: 0.5
        max-tokens: 500
        base-url: https://api.mistral.ai/v1
        completion-path: /chat/completions

app:
  ai:
    llm-logging:
      enabled: false
